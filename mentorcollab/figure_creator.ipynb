{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bb2772",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# side_by_side_bars.py\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_side_by_side(labels, data, series_labels=None, colors=None,\n",
    "                      total_width=0.8, figsize=(8, 4), ylabel=None, title=None,\n",
    "                      annotate=False, ylim=None):\n",
    "    \"\"\"\n",
    "    labels: list of group labels (length G)\n",
    "    data: sequence of length S, each item is a sequence of length G (S series)\n",
    "    series_labels: list of S labels for the legend\n",
    "    colors: list of S colors\n",
    "    total_width: fraction of group width occupied by bars (0-1)\n",
    "    \"\"\"\n",
    "    data = np.array(data)\n",
    "    if data.ndim == 1:\n",
    "        data = data[np.newaxis, :]\n",
    "    S, G = data.shape\n",
    "    indices = np.arange(G)\n",
    "    bar_w = total_width / S\n",
    "    # center the group around each index\n",
    "    offsets = (np.arange(S) - (S - 1) / 2) * bar_w\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    for i in range(S):\n",
    "        ax.bar(indices + offsets[i], data[i], width=bar_w,\n",
    "               label=(series_labels[i] if series_labels is not None else f\"Series {i+1}\"),\n",
    "               color=(colors[i] if colors is not None else None))\n",
    "\n",
    "    ax.set_xticks(indices)\n",
    "    ax.set_xticklabels(labels)\n",
    "    if ylabel:\n",
    "        ax.set_ylabel(ylabel)\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "    if ylim:\n",
    "        ax.set_ylim(ylim)\n",
    "    ax.legend()\n",
    "    if annotate:\n",
    "        for i in range(S):\n",
    "            for j in range(G):\n",
    "                ax.text(indices[j] + offsets[i], data[i, j], str(data[i, j]),\n",
    "                        ha='center', va='bottom', fontsize=8, rotation=0)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    groups = [\"No ICL System Prompt\", \"ICL System Prompt\"]\n",
    "    series = [\n",
    "        [20, 34],  # Series A\n",
    "        [25, 32],  # Series B\n",
    "        [25, 32],  # Series B\n",
    "    ]\n",
    "    plot_side_by_side(groups, series,\n",
    "                      series_labels=[\"Initial System Prompt\", \"Opt System Prompt 1\", \"Opt System Prompt 2\"],\n",
    "                      colors=[\"#4C72B0\", \"#55A868\", \"#C44E52\"],\n",
    "                      title=\"Answer Accuracy\",\n",
    "                      ylabel=\"Average Accuracy (%)\",\n",
    "                      annotate=True,\n",
    "                      total_width=0.2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "775501d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to 'mentor_comparison_SuperGPQA_gemma_3_4b_pt.pdf'\n",
      "Plot saved to 'mentor_comparison_SuperGPQA_llama3_1_8b.pdf'\n",
      "Plot saved to 'mentor_comparison_SuperGPQA_qwen3_8b_base.pdf'\n",
      "\n",
      "All plots saved to separate PDF files\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for all three generators\n",
    "# plot another six figures for supergpqa and commonsense\n",
    "data = {\n",
    "    'Gemma-3-4B-PT': {\n",
    "        'generator_accuracy': 13.80,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [9.60, 3.60, 18.20],\n",
    "        'Nudging\\n(γ=0.40)': [8.60, 9.20, 11.60],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [6.40, 2.60, 11.80],\n",
    "        'R-Stitch\\n(τ=0.03)': [11.20, 9.80, 16.60],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [12.60, 12.40, 15.20],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [15.20, 14.40, 14.80]\n",
    "    },\n",
    "    'Llama3.1-8B': {\n",
    "        'generator_accuracy': 18.00,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [8.80, 2.80, 21.00],\n",
    "        'Nudging\\n(γ=0.40)': [11.40, 9.00, 10.60],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [7.80, 2.80, 16.40],\n",
    "        'R-Stitch\\n(τ=0.03)': [10.80, 10.20, 16.60],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [17.00, 16.60, 16.80],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [17.00, 17.40, 15.40]\n",
    "    },\n",
    "    'Qwen3-8B-Base': {\n",
    "        'generator_accuracy': 15.40,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [13.20, 13.00, 18.60],\n",
    "        'Nudging\\n(γ=0.40)': [11.40, 10.00, 14.40],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [15.40, 15.20, 12.80],\n",
    "        'R-Stitch\\n(τ=0.03)': [10.20, 10.40, 15.80],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [17.20, 16.20, 18.60],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [16.80, 16.80, 17.60]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Colors for different methods\n",
    "colors = {\n",
    "    'Average Decoding': '#8B4513',\n",
    "    'Nudging\\n(γ=0.40)': '#FF6B6B',\n",
    "    'CoSD\\n(α=0.50, β=0.50)': '#4ECDC4',\n",
    "    'R-Stitch\\n(τ=0.03)': '#95E1D3',\n",
    "    'MENTORCOLLAB-FREE\\n(ρ=25%)': '#F38181',\n",
    "    'MENTORCOLLAB-MLP\\n(ρ=25%)': '#AA96DA'\n",
    "}\n",
    "\n",
    "# Methods list\n",
    "methods = ['Average Decoding', 'Nudging\\n(γ=0.40)', 'CoSD\\n(α=0.50, β=0.50)', \n",
    "           'R-Stitch\\n(τ=0.03)', 'MENTORCOLLAB-FREE\\n(ρ=25%)', 'MENTORCOLLAB-MLP\\n(ρ=25%)']\n",
    "\n",
    "# Create separate PDF for each generator\n",
    "for generator_name in ['Gemma-3-4B-PT', 'Llama3.1-8B', 'Qwen3-8B-Base']:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    plot_data = data[generator_name]\n",
    "    n_mentors = len(plot_data['mentors'])\n",
    "    n_methods = len(methods)\n",
    "    \n",
    "    # Bar width and positions\n",
    "    bar_width = 0.13\n",
    "    x_positions = np.arange(n_mentors)\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        values = plot_data[method]\n",
    "        offset = (i - n_methods/2 + 0.5) * bar_width\n",
    "        bars = ax.bar(x_positions + offset, values, bar_width, \n",
    "                     label=method.replace('\\n', ' '), \n",
    "                     color=colors[method],\n",
    "                     edgecolor='black',\n",
    "                     linewidth=0.5)\n",
    "    \n",
    "    # Draw generator baseline (dashed grey line)\n",
    "    ax.axhline(y=plot_data['generator_accuracy'], color='grey', \n",
    "               linestyle='--', linewidth=2.5, \n",
    "               label=f'Generator ({plot_data[\"generator_accuracy\"]:.1f}%)',\n",
    "               zorder=0)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Mentor Model', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f'Generator: {generator_name} (SuperGPQA)', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(plot_data['mentors'], fontsize=11)\n",
    "    \n",
    "    # Set y-axis limits based on the generator\n",
    "    if generator_name == 'Qwen3-8B-Base':\n",
    "        ax.set_ylim(0, 50)\n",
    "        ax.set_yticks(np.arange(0, 51, 10))\n",
    "    else:\n",
    "        ax.set_ylim(0, 25)\n",
    "        ax.set_yticks(np.arange(0, 26, 5))\n",
    "    \n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5, axis='y')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=9, \n",
    "              framealpha=0.95, edgecolor='gray', fancybox=True, ncol=1)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save to separate PDF\n",
    "    filename = f'mentor_comparison_SuperGPQA_{generator_name.replace(\".\", \"_\").replace(\"-\", \"_\").lower()}.pdf'\n",
    "    plt.savefig(filename, format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "\n",
    "print(f\"\\nAll plots saved to separate PDF files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74fdedd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plot saved to 'mentor_comparison_commonsense_gemma_3_4b_pt.pdf'\n",
      "Plot saved to 'mentor_comparison_commonsense_llama3_1_8b.pdf'\n",
      "Plot saved to 'mentor_comparison_commonsense_qwen3_8b_base.pdf'\n",
      "\n",
      "All plots saved to separate PDF files\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data for all three generators\n",
    "# plot another six figures for supergpqa and commonsense\n",
    "data = {\n",
    "    'Gemma-3-4B-PT': {\n",
    "        'generator_accuracy': 24.07,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [3.73, 7.47, 5.39],\n",
    "        'Nudging\\n(γ=0.40)': [2.90, 9.96, 7.47],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [0.83, 3.73, 2.49],\n",
    "        'R-Stitch\\n(τ=0.03)': [4.98, 7.88, 1.66],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [23.24, 21.99, 19.09],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [25.73, 23.24, 26.97]\n",
    "    },\n",
    "    'Llama3.1-8B': {\n",
    "        'generator_accuracy': 30.29,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [3.73, 9.96, 6.64],\n",
    "        'Nudging\\n(γ=0.40)': [2.49, 11.62, 4.98],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [0.83, 3.73, 2.90],\n",
    "        'R-Stitch\\n(τ=0.03)': [2.49, 7.88, 2.07],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [31.54, 30.71, 32.78],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [33.61, 30.29, 26.56]\n",
    "    },\n",
    "    'Qwen3-8B-Base': {\n",
    "        'generator_accuracy': 54.77,\n",
    "        'mentors': ['Qwen3-14B', 'Qwen3-32B', 'R1-Distilled-\\nLlama-70B'],\n",
    "        'Average Decoding': [3.73, 12.45, 35.27],\n",
    "        'Nudging\\n(γ=0.40)': [18.26, 20.89, 22.41],\n",
    "        'CoSD\\n(α=0.50, β=0.50)': [7.05, 15.77, 15.77],\n",
    "        'R-Stitch\\n(τ=0.03)': [2.90, 9.54, 3.32],\n",
    "        'MENTORCOLLAB-FREE\\n(ρ=25%)': [51.87, 49.79, 54.77],\n",
    "        'MENTORCOLLAB-MLP\\n(ρ=25%)': [42.32, 49.79, 48.55]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Colors for different methods\n",
    "colors = {\n",
    "    'Average Decoding': '#8B4513',\n",
    "    'Nudging\\n(γ=0.40)': '#FF6B6B',\n",
    "    'CoSD\\n(α=0.50, β=0.50)': '#4ECDC4',\n",
    "    'R-Stitch\\n(τ=0.03)': '#95E1D3',\n",
    "    'MENTORCOLLAB-FREE\\n(ρ=25%)': '#F38181',\n",
    "    'MENTORCOLLAB-MLP\\n(ρ=25%)': '#AA96DA'\n",
    "}\n",
    "\n",
    "# Methods list\n",
    "methods = ['Average Decoding', 'Nudging\\n(γ=0.40)', 'CoSD\\n(α=0.50, β=0.50)', \n",
    "           'R-Stitch\\n(τ=0.03)', 'MENTORCOLLAB-FREE\\n(ρ=25%)', 'MENTORCOLLAB-MLP\\n(ρ=25%)']\n",
    "\n",
    "# Create separate PDF for each generator\n",
    "for generator_name in ['Gemma-3-4B-PT', 'Llama3.1-8B', 'Qwen3-8B-Base']:\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    plot_data = data[generator_name]\n",
    "    n_mentors = len(plot_data['mentors'])\n",
    "    n_methods = len(methods)\n",
    "    \n",
    "    # Bar width and positions\n",
    "    bar_width = 0.13\n",
    "    x_positions = np.arange(n_mentors)\n",
    "    \n",
    "    # Plot bars for each method\n",
    "    for i, method in enumerate(methods):\n",
    "        values = plot_data[method]\n",
    "        offset = (i - n_methods/2 + 0.5) * bar_width\n",
    "        bars = ax.bar(x_positions + offset, values, bar_width, \n",
    "                     label=method.replace('\\n', ' '), \n",
    "                     color=colors[method],\n",
    "                     edgecolor='black',\n",
    "                     linewidth=0.5)\n",
    "    \n",
    "    # Draw generator baseline (dashed grey line)\n",
    "    ax.axhline(y=plot_data['generator_accuracy'], color='grey', \n",
    "               linestyle='--', linewidth=2.5, \n",
    "               label=f'Generator ({plot_data[\"generator_accuracy\"]:.1f}%)',\n",
    "               zorder=0)\n",
    "    \n",
    "    # Formatting\n",
    "    ax.set_xlabel('Mentor Model', fontsize=14, fontweight='bold')\n",
    "    ax.set_ylabel('Accuracy (%)', fontsize=14, fontweight='bold')\n",
    "    ax.set_title(f'Generator: {generator_name} (Com2-hard Intervention)', fontsize=16, fontweight='bold', pad=20)\n",
    "    \n",
    "    ax.set_xticks(x_positions)\n",
    "    ax.set_xticklabels(plot_data['mentors'], fontsize=11)\n",
    "    \n",
    "    # Set y-axis limits based on the generator\n",
    "    if generator_name == 'Qwen3-8B-Base':\n",
    "        ax.set_ylim(0, 60)\n",
    "        ax.set_yticks(np.arange(0, 61, 10))\n",
    "    else:\n",
    "        ax.set_ylim(0, 40)\n",
    "        ax.set_yticks(np.arange(0, 41, 5))\n",
    "    \n",
    "    ax.grid(True, alpha=0.3, linestyle='-', linewidth=0.5, axis='y')\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5), fontsize=9, \n",
    "              framealpha=0.95, edgecolor='gray', fancybox=True, ncol=1)\n",
    "    \n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save to separate PDF\n",
    "    filename = f'mentor_comparison_commonsense_{generator_name.replace(\".\", \"_\").replace(\"-\", \"_\").lower()}.pdf'\n",
    "    plt.savefig(filename, format='pdf', bbox_inches='tight', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Plot saved to '{filename}'\")\n",
    "\n",
    "print(f\"\\nAll plots saved to separate PDF files\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
